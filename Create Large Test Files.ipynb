{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Large HMDA Submission Test Files\n",
    "\n",
    "This notebook demonstrates a function for creating large HMDA submission test files using 1000 row clean files for bank 1 and bank 0. The function concatenates the files together, creates unique Universal Loan Identifiers (ULIs) with a check digit, and generates a submission file with a specified number of LAR rows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The following code imports the required packages.\n",
    "\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import string\n",
    "import time\n",
    "import yaml\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The function below generates a random character string with a given length to create loan identifiers.\n",
    "def char_string_gen(length):\n",
    "    return ''.join(random.choice(string.ascii_uppercase + string.digits) for _ in range(length))\n",
    "\n",
    "#This function returns a check digit for a given character string. \n",
    "def check_digit_gen(valid=True, ULI=None):\n",
    "\t\t\"\"\"Generates a check digit for a ULI in accordance with\n",
    "\t\thttps://www.consumerfinance.gov/eregulations/diff/1003-C/2015-26607_20170101/2015-26607_20180101?from_version=2015-26607_20170101#1003-C-1\"\"\"\n",
    "\t\tif ULI is None:\n",
    "\t\t\traise ValueError(\"a ULI must be supplied\")\n",
    "\t\t#GENERATING A CHECK DIGIT\n",
    "\t\t#Step 1: Starting with the leftmost character in the string that consists of the combination of the\n",
    "\t\t#Legal Entity Identifier (LEI) pursuant to ยง 1003.4(a)(1)(i)(A) and the additional characters identifying the\n",
    "\t\t#covered loan or application pursuant to ยง 1003.4(a)(1)(i)(B), replace each alphabetic character with numbers\n",
    "\t\t#in accordance with Table I below to obtain all numeric values in the string.\n",
    "\t\t\n",
    "\t\t\n",
    "\t\t#1: convert letters to digits\n",
    "\t\t#2: append '00' to right of string\n",
    "\t\t#3:Apply the mathematical function mod=(n, 97) where n= the number obtained in step 2 above and 97 is the divisor.\n",
    "\t\t#3a: Alternatively, to calculate without using the modulus operator, divide the numbers in step 2 above by 97.\n",
    "\t\t#   Truncate the remainder to three digits and multiply it by .97. Round the result to the nearest whole number.\n",
    "\t\t#4: Subtract the result in step 3 from 98. If the result is one digit, add a leading 0 to make it two digits.\n",
    "\t\t#5: The two digits in the result from step 4 is the check digit. Append the resulting check digit to the\n",
    "\t\t#   rightmost position in the combined string of characters described in step 1 above to generate the ULI.\n",
    "\t\t\n",
    "\t\t#digit_vals contains the conversion of numbers to letters\n",
    "\t\tdigit_vals = {\n",
    "\t\t'A':10, 'H':17,'O':24,'V':31,'B':11,'I':18,'P':25,'W':32,'C':12,'J':19,'Q':26,'X':33,'D':13,'K':20,'R':27,'Y':34,\n",
    "\t\t'E':14,'L':21,'S':28,'Z':35,'F':15,'M':22,'T':29,'G':16,'N':23,'U':30}\n",
    "\t\t\n",
    "\t\tuli_chars = list(ULI)\n",
    "\t\tmod_uli_chars = []\n",
    "\t\tfor char in uli_chars:\n",
    "\t\t\tif char.upper() in digit_vals.keys():\n",
    "\t\t\t\tmod_uli_chars.append(str(digit_vals[char.upper()]))\n",
    "\t\t\telse:\n",
    "\t\t\t\tmod_uli_chars.append(char)\n",
    "\t\tmod_uli_chars.append('00') \n",
    "\t\tdigit_base = int(\"\".join(mod_uli_chars))\n",
    "\t\tdigit_modulo = digit_base % 97\n",
    "\t\tcheck_digit = 98 - digit_modulo\n",
    "\n",
    "\t\tif valid:\n",
    "\t\t\treturn str(check_digit).zfill(2) #left pad check digit with 0 if length is less than 2\n",
    "\t\telse:\n",
    "\t\t\treturn str(check_digit+6).zfill(2)[:2] #return a bad check digit (used in edit testing)\n",
    "\n",
    "#This function checks whether character strings in a column are unique to each other. \n",
    "#When column strings are unique, the function returns a \"Passed\" statement.\n",
    "#If they are not, it returns a \"Failed\" statement. \n",
    "def uli_check(df=None):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function passes in a single column dataframe to determine whether values within the column\n",
    "    are unique. \n",
    "    \n",
    "    The function returns a \"Passed\" statement if they are, and returns a \"Failed\" statement if the values\n",
    "    are not unique. \n",
    "    \"\"\"\n",
    "    \n",
    "    df['unique'] = df\n",
    "    if len(df['unique'].unique()) == len(df.index): #Checks whether column values are unique. \n",
    "        statement = \"Unique Values: Passed\"\n",
    "    else: \n",
    "        statement = \"Unique Values: Failed\"\n",
    "    print(statement)\n",
    "    return df.drop('unique', axis = 1) #Drops the unique values column. \n",
    "    print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Clean Test Files\n",
    "\n",
    "The following defines a function that creates clean test files. The function uses 1000 row clean test files located in the repository for Bank 0 and Bank 1 to duplicate LAR data to produce data with a desired number of rows, and provide unique ULI's for each row. Test files may be created with rows as multiples of 1000. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "def large_clean_test_files(bank=None, file=file, count=None):\n",
    "    \n",
    "    \"\"\"\n",
    "    Creates clean HMDA submission test files in multiples of 1000, specified by the count variable. \n",
    "    The function requires a count, and a specification for the test bank, either '0' or '1.'\n",
    "    \n",
    "    The function replicates LAR data from two clean test files in the repository.\n",
    "    \"\"\"\n",
    "   #Checks whether the count is a multiple of 1000.  \n",
    "    if (count % 1000) != 0:\n",
    "        statement = \"Please specify a count in a multiple of 1000\"\n",
    "        return print(statement)\n",
    "    #Establishes the case for bank = 0. \n",
    "    if bank == 0:\n",
    "        file = \"clean_file_1000_rows_Bank0.txt\" \n",
    "        with open(file, 'r+' ) as f: #Opens the 1000 row file for Bank 0. \n",
    "            ts_row = f.readline() #Reading in the first row as the Transmittal Sheet submission. \n",
    "            lar_rows = f.readlines() #Reading in the other rows as the LAR submission.  \n",
    "        with open(\"edits_files/lar_rows.txt\", 'w') as out_lar: #Writes a file of LAR data. \n",
    "            out_lar.writelines(lar_rows)\n",
    "        with open(\"edits_files/ts_row.txt\", 'w') as out_ts: #Writes a file of TS data. \n",
    "            out_ts.writelines(ts_row)\n",
    "        with open('schemas/lar_schema.json') as d: #Loads in the schema for the LAR file as a dataframe. \n",
    "            data = json.load(d)\n",
    "            data = pd.DataFrame(data)\n",
    "\n",
    "        #Reads in the LAR data as a dataframe, as object values without converting NA values to \n",
    "        #Not a Number Values. \n",
    "        df = pd.read_csv('edits_files/lar_rows.txt', delimiter = \"|\", header = None, dtype = 'object',\n",
    "                         keep_default_na=False)\n",
    "        df.columns = data['field'] #Takes the field names from the LAR schema as column names. \n",
    "        \n",
    "        #Concatenates data to produce the desired number of rows in a new LAR dataframe. \n",
    "        df = pd.concat([df]*int((count/1000)), ignore_index = True) \n",
    "        \n",
    "        #Creates a list of unique ULI's for Bank 0, and checks to determine that ULI's are unique.\n",
    "        uli_1 = {'uli':list(['B90YWS6AFX2LGWOXJ1LD']*int((count)))}\n",
    "        df1 = pd.DataFrame(uli_1)\n",
    "        df1[\"uli\"] = df1.apply(lambda x: x.uli + char_string_gen(23), axis = 1)\n",
    "        df1['uli'] = df1.apply(lambda x: x.uli + check_digit_gen(ULI = x.uli), axis = 1)\n",
    "        uli_check(df1)\n",
    "\n",
    "        #Replaces ULI's in the new LAR dataframe with the unique ULI's.  \n",
    "        df['uli'] = df1['uli']\n",
    "        \n",
    "        #Creates a new LAR csv file with the new LAR data with unique ULI's. \n",
    "        df.to_csv(\"lar_\" + str(count) + \".txt\", sep = \"|\", index = False, header= None)\n",
    "        \n",
    "        #The following appends the new LAR data into the TS file created earlier. \n",
    "        #The new file is renamed \"clean_file_(count)_row_Bank0.txt.\"\n",
    "        #New clean files are placed in the \"edits_files/clean_files/bank0/\" directory.\n",
    "        filepath = \"edits_files/clean_files/bank0/\"\n",
    "        os.makedirs(os.path.dirname(filepath), exist_ok=True)\n",
    "        \n",
    "        with open(\"lar_\" + str(count) + \".txt\", 'r' ) as f:\n",
    "            lar_count = f.readlines()\n",
    "\n",
    "        with open(\"edits_files/ts_row.txt\", 'a') as append_lar:\n",
    "            append_lar.writelines(lar_count)\n",
    "\n",
    "        os.remove(\"lar_\" + str(count) + \".txt\")\n",
    "        os.rename(\"edits_files/ts_row.txt\", \"edits_files/clean_files/bank0/clean_file_\" + \n",
    "                         str(count) + \"_rows_Bank0.txt\")\n",
    "        return print(str(\"{:,}\".format(count)) + \" Row File Created for Bank \" + str(bank))\n",
    "\n",
    "    #Establishes the case for bank = 1.\n",
    "    elif bank == 1:\n",
    "        file = \"clean_file_1000_rows_Bank1.txt\" #Opens the 1000 row file for Bank 1. \n",
    "        with open(file, 'r' ) as f:\n",
    "            ts_row = f.readline() #Reading in the first row as the Transmittal Sheet submission. \n",
    "            lar_rows = f.readlines() #Reading in the other rows as the LAR submission.\n",
    "        with open(\"edits_files/lar_rows.txt\", 'w') as out_lar: #Writes a file of LAR data.\n",
    "            out_lar.writelines(lar_rows) \n",
    "        with open(\"edits_files/ts_row.txt\", 'w') as out_ts: #Writes a file of TS data. \n",
    "            out_ts.writelines(ts_row)\n",
    "        with open('schemas/lar_schema.json') as d: #Loads in the schema for the LAR file as a dataframe.\n",
    "            data = json.load(d)\n",
    "            data = pd.DataFrame(data)\n",
    "\n",
    "        #Reads in the LAR data as a dataframe, as object values without converting NA values to \n",
    "        #Not a Number Values. \n",
    "        df = pd.read_csv('edits_files/lar_rows.txt', delimiter = \"|\", header = None, dtype = 'object',\n",
    "                         keep_default_na=False)\n",
    "        df.columns = data['field']\n",
    "        \n",
    "        #Concatenates data to produce the desired number of rows in a new LAR dataframe. \n",
    "        df = pd.concat([df]*int((count/1000)), ignore_index = True)  \n",
    "\n",
    "        #Creates a list of unique ULI's for Bank 1, and checks to determine that ULI's are unique.\n",
    "        uli_1 = {'uli':list(['BANK1LEIFORTEST12345']*int((count)))}\n",
    "        df1 = pd.DataFrame(uli_1)\n",
    "        df1[\"uli\"] = df1.apply(lambda x: x.uli + char_string_gen(23), axis = 1)\n",
    "        df1['uli'] = df1.apply(lambda x: x.uli + check_digit_gen(ULI = x.uli), axis = 1)\n",
    "        uli_check(df1)\n",
    "        \n",
    "        #Replaces ULI's in the new LAR dataframe with the unique ULI's.  \n",
    "        df['uli'] = df1['uli']\n",
    "        \n",
    "        #Creates a new LAR csv file with the new LAR data with unique ULI's. \n",
    "        df.to_csv(\"lar_\" + str(count) + \".txt\", sep = \"|\", index = False, header= None)\n",
    "\n",
    "        #The following appends the new LAR data into the TS file created earlier. \n",
    "        #The new file is renamed \"clean_file_(count)_row_Bank1.txt.\"\n",
    "        #New clean files are placed in the \"edits_files/clean_files/bank1/\" directory.\n",
    "        \n",
    "        filepath = \"edits_files/clean_files/bank1/\"\n",
    "        os.makedirs(os.path.dirname(filepath), exist_ok=True)\n",
    "        \n",
    "        with open(\"lar_\" + str(count) + \".txt\", 'r' ) as f:\n",
    "            lar_count = f.readlines()\n",
    "\n",
    "        with open(\"edits_files/ts_row.txt\", 'a') as append_lar:\n",
    "            append_lar.writelines(lar_count)\n",
    "\n",
    "        os.remove(\"lar_\" + str(count) + \".txt\")\n",
    "        os.rename(\"edits_files/ts_row.txt\", \"edits_files/clean_files/bank1/clean_file_\" + \n",
    "                         str(count) + \"_rows_Bank1.txt\")\n",
    "        return print(str(\"{:,}\".format(count)) + \" Row File Created for Bank \" + str(bank))\n",
    "\n",
    "    else:\n",
    "        statement = \"Please list bank as '0' or '1'\"\n",
    "        return print(statement)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Values: Passed\n",
      "3,000 Row File Created for Bank 1\n"
     ]
    }
   ],
   "source": [
    "large_clean_test_files(bank = 1, count = 3000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Clean Test Files With Specified Counts in a List\n",
    "A loop may be used to create clean large test files with the counts in a list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Values: Passed\n",
      "1,000 Row File Created for Bank 0\n",
      "Unique Values: Passed\n",
      "5,000 Row File Created for Bank 0\n",
      "Unique Values: Passed\n",
      "10,000 Row File Created for Bank 0\n",
      "Unique Values: Passed\n",
      "50,000 Row File Created for Bank 0\n",
      "Unique Values: Passed\n",
      "100,000 Row File Created for Bank 0\n"
     ]
    }
   ],
   "source": [
    "counts = [1000, 5000, 10000, 50000, 100000]\n",
    "\n",
    "for count in counts:\n",
    "    large_clean_test_files(bank = 0, count = count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Values: Passed\n",
      "1,000 Row File Created for Bank 1\n",
      "Unique Values: Passed\n",
      "5,000 Row File Created for Bank 1\n",
      "Unique Values: Passed\n",
      "10,000 Row File Created for Bank 1\n",
      "Unique Values: Passed\n",
      "50,000 Row File Created for Bank 1\n",
      "Unique Values: Passed\n",
      "100,000 Row File Created for Bank 1\n"
     ]
    }
   ],
   "source": [
    "counts = [1000, 5000, 10000, 50000, 100000]\n",
    "\n",
    "for count in counts:\n",
    "    large_clean_test_files(bank = 1, count = count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
