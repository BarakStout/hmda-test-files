{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/roellk/Desktop/HMDA/hmda-test-files/python\r\n"
     ]
    }
   ],
   "source": [
    "#2018 HMDA Edit Testing File Generator\n",
    "from collections import OrderedDict\n",
    "from io import StringIO\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "#custom imports\n",
    "import lar_constraints\n",
    "import lar_generator\n",
    "from rules_engine import rules_engine\n",
    "from test_file_generator import test_data\n",
    "import utils\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2018 Filing Instruction Guide: https://www.consumerfinance.gov/data-research/hmda/static/for-filers/2018/2018-HMDA-FIG.pdf\n",
    "\n",
    "use_cols = ['name', 'metDivName', 'countyFips', 'geoIdMsa', 'metDivFp', 'smallCounty', 'tracts']\n",
    "cbsa_cols = ['name', 'metDivName', 'state', 'countyFips', 'county', 'tracts','geoIdMsa', 'metDivFp', 'smallCounty', \n",
    "             'stateCode', 'tractDecimal']\n",
    "cbsas = pd.read_csv('../dependancies/tract_to_cbsa_2015.txt', usecols=use_cols, delimiter='|', \n",
    "                    header=None, names=cbsa_cols, dtype=str) #load tract to CBSA data from platform file\n",
    "cbsas[\"tractFips\"] = cbsas.countyFips + cbsas.tracts\n",
    "counties = list(cbsas.countyFips)\n",
    "tracts = list(cbsas.tractFips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load schemas for LAR and transmittal sheet\n",
    "lar_schema_df = pd.DataFrame(json.load(open(\"../schemas/lar_schema.json\", \"r\")))\n",
    "ts_schema_df = pd.DataFrame(json.load(open(\"../schemas/ts_schema.json\", \"r\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lar_gen = lar_generator.lar_gen(lar_schema_df, ts_schema_df, counties=counties, tracts=tracts) #instantiate generator\n",
    "lar_const = lar_constraints.lar_constraints(counties=counties, tracts=tracts)#instantiate constraints\n",
    "lar_validator = rules_engine(lar_schema=lar_schema_df, ts_schema=ts_schema_df, tracts=tracts, counties=counties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set parameters for data creation\n",
    "file_length = 5 #set number of rows in test file\n",
    "first = True\n",
    "lei = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a sample TS row\n",
    "#set dummy values for TS row\n",
    "def make_ts_row(file_length, lei):\n",
    "    ts_row = OrderedDict()\n",
    "    ts_row[\"record_id\"]=\"1\"\n",
    "    ts_row[\"inst_name\"]=\"Ficus Bank\"\n",
    "    ts_row[\"calendar_year\"]= \"2018\"\n",
    "    ts_row[\"calendar_quarter\"]=\"4\"\n",
    "    ts_row[\"contact_name\"]=\"Mr. Smug Pockets\"\n",
    "    ts_row[\"contact_tel\"]=\"555-555-5555\"\n",
    "    ts_row[\"contact_email\"]=\"pockets@ficus.com\"\n",
    "    ts_row[\"contact_street_address\"]=\"1234 Ficus Lane\"\n",
    "    ts_row[\"office_city\"]=\"Ficusville\"\n",
    "    ts_row[\"office_state\"]=\"UT\"\n",
    "    ts_row[\"office_zip\"]=\"84096\"\n",
    "    ts_row[\"federal_agency\"]=\"9\"\n",
    "    ts_row[\"lar_entries\"]= str(file_length)\n",
    "    ts_row[\"tax_id\"]=\"01-0123456\"\n",
    "    ts_row[\"lei\"]=str(lei)\n",
    "    return ts_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_const_list():\n",
    "    \"\"\"Creates a list of constraints from the functions in the lar_constraints object.\"\"\"\n",
    "    constraints = [] \n",
    "    for func in dir(lar_const):\n",
    "        if func[:1] in (\"s\", \"v\") and func[1:4].isdigit()==True:\n",
    "            constraints.append(func)\n",
    "    return constraints\n",
    "            \n",
    "def constraints_loop(constraints=[], row=None, row_base=None):\n",
    "    for const in constraints:\n",
    "        row = apply_constraint(row, const)\n",
    "        diff = get_diff(row, row_base)\n",
    "    return row\n",
    "\n",
    "def apply_constraint(row, func):\n",
    "    \"\"\"Applies all constraints in the constrains list and returns a LAR row in dictionary format.\"\"\"\n",
    "    row_start = row.copy()\n",
    "    row = getattr(lar_const, func)(row) #apply constraint to row\n",
    "    diff_1, diff_2 = get_diff(row, row_start)\n",
    "    if len(diff_1) > 0:\n",
    "        print(str(func))\n",
    "        print(diff_1, \"\\n\\n\", diff_2)\n",
    "    return row\n",
    "\n",
    "def get_diff(row, row_base):\n",
    "    \"\"\"Checks the difference between an initial row and the row after constraints are applied\"\"\"\n",
    "    initial_row = set(row_base.items()) #convert initial row to set\n",
    "    changed_row = set(row.items()) #convert constrained row to set\n",
    "    diff_1 = (changed_row - initial_row) #subtract row sets to show changes from constraint funcs\n",
    "    diff_2 = (initial_row - changed_row)\n",
    "    return diff_1, diff_2\n",
    "\n",
    "def validation(row, ts_row):\n",
    "    \"\"\"\"\"\"\n",
    "    lar_data = pd.DataFrame(row, index=[1])\n",
    "    ts_data = pd.DataFrame(ts_row, index=[0])\n",
    "    rules_check = rules_engine(lar_schema=lar_schema_df, ts_schema=ts_schema_df, tracts=tracts, \n",
    "                             counties=counties) #instantiate edits rules engine\n",
    "    rules_check.load_lar_data(lar_data)\n",
    "    rules_check.load_ts_data(ts_data)\n",
    "    for func in dir(rules_check):\n",
    "        if func[:1] in (\"s\", \"v\") and func[1:4].isdigit()==True:\n",
    "            #print(\"applying:\", func)\n",
    "            getattr(rules_check, func)()\n",
    "    return rules_check.results\n",
    "\n",
    "def write_file(ts_input=None, lar_input=None, directory=\"../edits_files/\", name=\"passes_all.txt\"):\n",
    "    \"\"\"Takes a TS row as a dictionary and LAR data as a dataframe. Writes LAR data to file and \n",
    "    re-reads it to combine with TS data to make a full file.\"\"\"\n",
    "    #make directories for files if they do not exist\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    #write LAR dataframe to file\n",
    "    parts_dir = directory+\"file_parts/\"\n",
    "    if not os.path.exists(parts_dir):\n",
    "        os.makedirs(parts_dir)\n",
    "        \n",
    "    lar_input.to_csv(parts_dir + \"lar_data.txt\", sep=\"|\", header=False, index=False, index_label=False)\n",
    "    #load LAR data as file rows\n",
    "    with open(parts_dir + \"lar_data.txt\", 'r') as lar_data:\n",
    "        lar = lar_data.readlines()\n",
    "\n",
    "    with open(directory + name, 'w') as final_file:\n",
    "        final_file.write(\"|\".join(ts_input.values())+\"\\n\")\n",
    "        for line in lar:\n",
    "            final_file.write(\"{line}\".format(line=line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "making new row 0\n",
      "\n",
      " **************************************************\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "34",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-e1bce76aaba6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlar_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_row\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlei\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlei\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#generate new LEI. The same LEI must be used for each row\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlar_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_row\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#create new row\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mlei\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"lei\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#copy LEI from previous row\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/HMDA/hmda-test-files/python/lar_generator.py\u001b[0m in \u001b[0;36mmake_row\u001b[0;34m(self, lei)\u001b[0m\n\u001b[1;32m    195\u001b[0m                 \u001b[0mvalid_lar_row\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"street_address\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstreet_addy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mvalid_lar_row\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"city\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m                 \u001b[0mvalid_lar_row\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"state\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_codes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m                 \u001b[0mvalid_lar_row\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"zip_code\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzip_code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m                 \u001b[0mvalid_lar_row\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"county\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcounty_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/homebrew/Cellar/python3/3.6.2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/random.py\u001b[0m in \u001b[0;36mchoice\u001b[0;34m(self, seq)\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cannot choose from an empty sequence'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 34"
     ]
    }
   ],
   "source": [
    "first = True\n",
    "for i in range(0, file_length): #loop over file length\n",
    "    print(\"making new row {row_num}\\n\\n\".format(row_num=i), \"*\"*50)\n",
    "    if lei:\n",
    "        row = lar_gen.make_row(lei=lei) #generate new LEI. The same LEI must be used for each row\n",
    "    else:\n",
    "        row = lar_gen.make_row() #create new row\n",
    "        \n",
    "    lei = row[\"lei\"] #copy LEI from previous row\n",
    "    iters = 1 #start iteration count for checking diff time\n",
    "\n",
    "    ts_row = make_ts_row(file_length, lei) #create dictionary of TS row fields\n",
    "    stop = False\n",
    "    #flag for starting the LAR dataframe\n",
    "    while stop == False:\n",
    "        row_base = row.copy() #copy row to enable diff\n",
    "        res = pd.DataFrame(validation(row, ts_row))\n",
    "        print(res[res.status==\"failed\"])\n",
    "        if len(res[res.status==\"failed\"])<=0:\n",
    "            stop = True\n",
    "        else:\n",
    "            print(\"\\nstarting constraints iteration {iter}\".format(iter=iters))\n",
    "            row = constraints_loop(get_const_list(), row, row_base)\n",
    "        iters+=1\n",
    "    \n",
    "    if first: #create first row of dataframe\n",
    "        lar_frame = pd.DataFrame(row, index=[1])\n",
    "        first = False\n",
    "        print(\"finished row\\n\")\n",
    "    else: #add additional rows to dataframe\n",
    "        #print(\"concating\")\n",
    "        print(\"finished row\\n\")\n",
    "        new_lar = pd.DataFrame(row, index=[1])\n",
    "        lar_frame = pd.concat([lar_frame, new_lar], axis=0)\n",
    "        \n",
    "#lar_frame.reset_index(inplace=True) #reset index\n",
    "#lar_frame.drop(\"index\", inplace=True, axis=1) #drop additional index column\n",
    "print(\"LAR dataframe complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check validity and syntax of data using rules_engine\n",
    "#instantiate edits rules engine\n",
    "validator = rules_engine(lar_schema=lar_schema_df, ts_schema=ts_schema_df, tracts=tracts, counties=counties) \n",
    "#load data to validator engine\n",
    "validator.load_lar_data(lar_frame)\n",
    "validator.load_ts_data(pd.DataFrame(ts_row, index=[0], columns=validator.ts_field_names))\n",
    "#check data\n",
    "for func in dir(validator):\n",
    "    if func[:1] in (\"s\", \"v\") and func[1:4].isdigit()==True:\n",
    "        #print(\"applying:\", func)\n",
    "        getattr(validator, func)()\n",
    "\n",
    "#get validation results\n",
    "results_df = pd.DataFrame(validator.results)\n",
    "results_df[results_df.status==\"failed\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Quality and Macro field interrelationship constraints:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write sample file to disk\n",
    "write_file(ts_input=ts_row, lar_input=lar_frame, name=\"passes_10_rows.txt\") #writes created file to disk\n",
    "lar_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_maker = test_data(ts_schema_df, lar_schema_df)\n",
    "ts_data, lar_data = utils.read_data_file(path=\"../edits_files/\", data_file=\"passes_10_rows.txt\")\n",
    "file_maker.load_data_frames(ts_data, lar_data)\n",
    "file_maker.s300_1_file()\n",
    "file_maker.s300_2_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validator.read_data_file(path=\"../edits_files/syntax/\", data_file=\"s300_2.txt\")\n",
    "validator.reset_results()\n",
    "#check data\n",
    "for func in dir(validator):\n",
    "    if func[:1] in (\"s\", \"v\") and func[1:4].isdigit()==True:\n",
    "        #print(\"applying:\", func)\n",
    "        getattr(validator, func)()\n",
    "\n",
    "#get validation results\n",
    "results_df = pd.DataFrame(validator.results)\n",
    "results_df[results_df.status==\"failed\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
