{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Custom Row HMDA Submission Test Files\n",
    "\n",
    "This notebook demonstrates a class for creating custom row HMDA submission test files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The following code imports the required packages.\n",
    "import math\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import string\n",
    "import time\n",
    "import yaml\n",
    "import shutil as sh\n",
    "\n",
    "from lar_generator import lar_gen #Imports lar_gen class. \n",
    "lg = lar_gen() #Instantiates lar_gen class as lg. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom_Test_Files Class\n",
    "\n",
    "The following demonstrates a function from the Custom_Test_Files class that creates test files with a custom number of rows. The class is instantiated with an existing file to create a new file with a specified row count. This set of functions is from the Custom_Test_Files class defined below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom_Test_Files Object Instantiated.\n",
      "Unique ULIs Assigned for Bank1\n",
      "4,000 Row File Created for Bank1 File Path: ../edits_files/new_files/clean_file_4000_rows_Bank1.txt\n"
     ]
    }
   ],
   "source": [
    "#The class is instantiated with an existing clean file\n",
    "cf = Custom_Test_Files(filename = \"../edits_files/file_parts/clean_file_1000_rows_Bank1.txt\")\n",
    "cf.create_file(row_count=4000, save_file = \"../edits_files/new_files/clean_file_4000_rows_Bank1.txt\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Custom_Test_Files(object):\n",
    "    \n",
    "    \"\"\"Returns a Custom_Tesst_Files object with a set of functions and parameters to create submission files\n",
    "    with a specified number of rows.\"\"\"\n",
    "    \n",
    "    def __init__(self, filename):\n",
    "        self.filename = filename #Instantiates a file to build \n",
    "        print(\"Custom_Test_Files Object Instantiated.\")\n",
    "            \n",
    "    def create_file(self, row_count=None, save_file=None):\n",
    "        \"\"\"\n",
    "        Creates a new custom file, passing in a row count and filepath to save the created file. \n",
    "    \n",
    "        \"\"\"\n",
    "        ts_file = cf.separate_ts() #Stores the file path for TS data as ts_file. \n",
    "        lar_file = cf.separate_lar() #Stores the file path for LAR data as lar_file. \n",
    "        #Uses the get_rows function to create a dataframe of LAR and to add on the specified number of rows. \n",
    "        df = cf.get_rows(row_count=row_count, lar_file=lar_file) \n",
    "        #Uses the assign rows function to create unique ULI's. \n",
    "        df = cf.assign_uli(df=df, ts_file=ts_file)\n",
    "        #Places the dataframe of LAR in a file with a TS row. \n",
    "        cf.lar_to_hmda_file(ts_file=ts_file, df=df, save_file=save_file)\n",
    "    \n",
    "    def separate_ts(self):  \n",
    "        \"\"\"\n",
    "         Separates the Transmittal Sheet (TS) row from the submission file.\n",
    "         Saves the TS data as text files in the /edits_files/file_parts/ directory. \n",
    "        \n",
    "        \"\"\"\n",
    "        with open(self.filename, 'r+' ) as f: #Opening the submission file. \n",
    "            ts_row = f.readline() #Reading in the first row as the TS submission. \n",
    "            lar_rows = f.readlines() #Reading in the other rows as the LAR submission.  \n",
    "        with open(\"../edits_files/file_parts/ts_data.txt\", 'w') as out_ts: #Writes a file of TS data. \n",
    "            out_ts.writelines(ts_row)\n",
    "            \n",
    "        statement = \"\"\" TS file saved as: \"../edits_files/file_parts/lar_data.txt\" \"\"\"\n",
    "        ts_filepath = \"../edits_files/file_parts/ts_data.txt\"\n",
    "        return ts_filepath #returns a string of the TS filepath.\n",
    "    \n",
    "    def separate_lar(self):\n",
    "        with open(self.filename, 'r+' ) as f: #Opening the submission file. \n",
    "            ts_row = f.readline() #Reading in the first row as the TS submission. \n",
    "            lar_rows = f.readlines() #Reading in the other rows as the LAR submission.  \n",
    "        with open(\"../edits_files/file_parts/lar_data.txt\", 'w') as out_lar: #Writes a file of LAR data. \n",
    "            out_lar.writelines(lar_rows)\n",
    "        \n",
    "        #Prints the location of each data file. \n",
    "        statement = \"\"\"LAR file saved as: \"../edits_files/file_parts/lar_data.txt\" \"\"\"\n",
    "        \n",
    "        lar_filepath = \"../edits_files/file_parts/lar_data.txt\"\n",
    "        return lar_filepath #returns a string of the LAR filepath.\n",
    "    \n",
    "    def get_rows(self, lar_file=None, row_count=None):\n",
    "        \"\"\"\n",
    "        Returns a data frame of LAR data with a specified number of rows.\n",
    "        \n",
    "        \"\"\"\n",
    "        with open('../schemas/lar_schema.json') as d: #Loads in the schema for the LAR file as a dataframe. \n",
    "            headers = json.load(d)\n",
    "            headers = pd.DataFrame(headers)\n",
    "        #Reads in the data from lar_file. \n",
    "        df = pd.read_csv(lar_file, delimiter=\"|\", header=None, dtype='object',\n",
    "                         keep_default_na=False) \n",
    "        \n",
    "        df.columns = headers['field'] #Takes the field names from the LAR schema as column names.\n",
    "        \n",
    "        current_row = len(df.index) #Number of rows currently in the dataframe. \n",
    "\n",
    "        #Calculates a multiplier taking the ceiling function of desired row count over current row count. \n",
    "        multiplier = math.ceil(row_count/current_row)\n",
    "        \n",
    "        #Concatenates data to produce the number of rows by the multiplier in a new LAR dataframe. \n",
    "        df = pd.concat([df]*int(multiplier))\n",
    "        \n",
    "        #Drops the number of rows to the row count specified. \n",
    "        \n",
    "        if (row_count%current_row) == 0:\n",
    "            return df\n",
    "        else:\n",
    "            drop_rows = current_row - (row_count%current_row)\n",
    "            df = df[:-(drop_rows)]\n",
    "            return df\n",
    "         \n",
    "    def assign_uli(self, df=None, ts_file=None):\n",
    "        \"\"\"\n",
    "        Assigns new ULI's to a dataframe of lar rows, based on the bank number in the TS file. \n",
    "        \n",
    "        \"\"\"\n",
    "        #Reads in ts_file.\n",
    "        ts_df = pd.read_csv(ts_file, delimiter=\"|\", header=None, dtype='object',\n",
    "                         keep_default_na=False)\n",
    "        \n",
    "        #Stores the second column of the TS file as 'bank'. \n",
    "        bank = ts_df.iloc[0][1]\n",
    "        \n",
    "        #Assigns the number of rows in the dataframe to row_count. \n",
    "        df.reset_index()\n",
    "        row_count = len(df.index)\n",
    "        #Creates a new list of LEI's for the ULI column by bank.\n",
    "        if bank == 'Bank0': \n",
    "            unique_lei_for_uli = {'uli':list(['B90YWS6AFX2LGWOXJ1LD']*int((row_count)))}\n",
    "        \n",
    "        if bank == 'Bank1':\n",
    "            unique_lei_for_uli = {'uli':list(['BANK1LEIFORTEST12345']*int((row_count)))}\n",
    "        \n",
    "        uli_col = pd.DataFrame(unique_lei_for_uli) #Creates a dataframe of new ULI's.\n",
    "        #Amends the ULI's by adding up to 23 additional characters. \n",
    "        uli_col['uli'] = uli_col.apply(lambda x: x.uli + lg.char_string_gen(length = 23), axis=1)\n",
    "        #Adds a checkdigit to the end of the ULI. \n",
    "        uli_col['uli'] = uli_col.apply(lambda x: x.uli + lg.check_digit_gen(ULI=x.uli), axis=1)\n",
    "        #Checks whether ULI's are unique using the uli_check function. \n",
    "        \n",
    "        if self.uli_check(col = uli_col) is True:\n",
    "            df['uli'] = uli_col['uli'] #If unique, ULI's in the dataframe are replaced. \n",
    "            print(\"Unique ULIs Assigned for \" + str(bank))\n",
    "            return df\n",
    "        else: \n",
    "            #If not unique, the assign_uli function is re-run.\n",
    "            print(\"Re-Running\")\n",
    "            assign_uli(self, ts_file=ts_file, df=df)  \n",
    "    \n",
    "    def uli_check(self, col=None):\n",
    "        \"\"\"\n",
    "        Passes in a single column dataframe to determine whether values within the column\n",
    "        are unique. \n",
    "        \n",
    "        Returns a True statement if they are, and returns a False statement if not. \n",
    "        \"\"\"\n",
    "        col['unique'] = col\n",
    "        if len(col['unique'].unique()) == len(col.index): #Checks whether column values are unique. \n",
    "            return True\n",
    "        else: \n",
    "            return False\n",
    "        \n",
    "    def lar_to_hmda_file(self, df=None, ts_file=None, save_file=None):\n",
    "        \n",
    "        \"\"\"\n",
    "        Creates a HMDA submission file, passing in a dataframe of LAR rows, the TS file, and a filepath to store\n",
    "        the file. \n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        #Store the number of rows in the lar_rows dataframe. \n",
    "        row_count = len(df.index)\n",
    "        \n",
    "        #Replaces the lar_data text file with the lar_rows dataframe.\n",
    "        df.to_csv(\"../edits_files/file_parts/lar_data.txt\", sep=\"|\", index=False, header=None)\n",
    "\n",
    "\n",
    "        #Reads in TS file.\n",
    "        ts_df = pd.read_csv(ts_file, delimiter=\"|\", header=None, dtype='object',\n",
    "                         keep_default_na=False)\n",
    "        \n",
    "        #Stores the second column of the TS file as 'bank'. \n",
    "        bank = ts_df.iloc[0][1]\n",
    "        \n",
    "        #Creates a new file path to place the new HMDA submission file. \n",
    "        os.makedirs(os.path.dirname(save_file), exist_ok=True)\n",
    "        \n",
    "        #Copies the TS text file into the save filepath specified in the function and renames it. \n",
    "        sh.copyfile(ts_file, save_file)\n",
    "        \n",
    "        #Reads in lar_data text file and appends it to the Transmittal Sheet row in the new file. \n",
    "        with open(\"../edits_files/file_parts/lar_data.txt\", 'r' ) as f:\n",
    "            new_lars = f.readlines()\n",
    "\n",
    "        with open(save_file, 'a') as append_lar:\n",
    "            append_lar.writelines(new_lars)\n",
    "\n",
    "        \n",
    "        #Prints out a statement with the number of rows created, and the location of the new file. \n",
    "        statement1 = (str(\"{:,}\".format(row_count)) + \" Row File Created for \" + str(bank) + \n",
    "                      \" File Path: \" + str(save_file))\n",
    "    \n",
    "        return print(statement1)\n",
    "\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
